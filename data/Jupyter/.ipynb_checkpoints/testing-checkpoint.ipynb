{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "424fa6bb-26ea-4c8c-a44d-2b84f1881ced",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>225.039993</td>\n",
       "      <td>225.830002</td>\n",
       "      <td>223.880005</td>\n",
       "      <td>225.240005</td>\n",
       "      <td>207.534515</td>\n",
       "      <td>91366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>225.619995</td>\n",
       "      <td>226.750000</td>\n",
       "      <td>225.610001</td>\n",
       "      <td>226.580002</td>\n",
       "      <td>208.769211</td>\n",
       "      <td>78744400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>226.270004</td>\n",
       "      <td>226.580002</td>\n",
       "      <td>225.479996</td>\n",
       "      <td>226.399994</td>\n",
       "      <td>208.603333</td>\n",
       "      <td>78379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>226.529999</td>\n",
       "      <td>227.750000</td>\n",
       "      <td>225.899994</td>\n",
       "      <td>227.210007</td>\n",
       "      <td>209.349670</td>\n",
       "      <td>71559900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>226.910004</td>\n",
       "      <td>227.070007</td>\n",
       "      <td>226.419998</td>\n",
       "      <td>226.460007</td>\n",
       "      <td>208.658646</td>\n",
       "      <td>46939700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-24</th>\n",
       "      <td>237.179993</td>\n",
       "      <td>237.410004</td>\n",
       "      <td>234.559998</td>\n",
       "      <td>237.169998</td>\n",
       "      <td>219.477432</td>\n",
       "      <td>119209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-25</th>\n",
       "      <td>237.910004</td>\n",
       "      <td>238.949997</td>\n",
       "      <td>237.809998</td>\n",
       "      <td>238.550003</td>\n",
       "      <td>220.754486</td>\n",
       "      <td>76698300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-26</th>\n",
       "      <td>238.509995</td>\n",
       "      <td>239.529999</td>\n",
       "      <td>238.350006</td>\n",
       "      <td>238.399994</td>\n",
       "      <td>220.615677</td>\n",
       "      <td>84702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-27</th>\n",
       "      <td>238.770004</td>\n",
       "      <td>238.949997</td>\n",
       "      <td>237.979996</td>\n",
       "      <td>238.600006</td>\n",
       "      <td>220.800720</td>\n",
       "      <td>57410300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-28</th>\n",
       "      <td>238.899994</td>\n",
       "      <td>238.929993</td>\n",
       "      <td>237.929993</td>\n",
       "      <td>238.080002</td>\n",
       "      <td>220.319565</td>\n",
       "      <td>63532800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2017-01-03  225.039993  225.830002  223.880005  225.240005  207.534515   \n",
       "2017-01-04  225.619995  226.750000  225.610001  226.580002  208.769211   \n",
       "2017-01-05  226.270004  226.580002  225.479996  226.399994  208.603333   \n",
       "2017-01-06  226.529999  227.750000  225.899994  227.210007  209.349670   \n",
       "2017-01-09  226.910004  227.070007  226.419998  226.460007  208.658646   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2017-04-24  237.179993  237.410004  234.559998  237.169998  219.477432   \n",
       "2017-04-25  237.910004  238.949997  237.809998  238.550003  220.754486   \n",
       "2017-04-26  238.509995  239.529999  238.350006  238.399994  220.615677   \n",
       "2017-04-27  238.770004  238.949997  237.979996  238.600006  220.800720   \n",
       "2017-04-28  238.899994  238.929993  237.929993  238.080002  220.319565   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2017-01-03   91366500  \n",
       "2017-01-04   78744400  \n",
       "2017-01-05   78379000  \n",
       "2017-01-06   71559900  \n",
       "2017-01-09   46939700  \n",
       "...               ...  \n",
       "2017-04-24  119209900  \n",
       "2017-04-25   76698300  \n",
       "2017-04-26   84702500  \n",
       "2017-04-27   57410300  \n",
       "2017-04-28   63532800  \n",
       "\n",
       "[81 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf #historical stock data lib\n",
    "import pandas as pd #pandas dataframe lib\n",
    "import dask.dataframe as dd #dask dataframe lib\n",
    "\n",
    "spy = yf.download(\"spy\", start=\"2017-01-01\", end=\"2017-04-30\")\n",
    "\n",
    "spy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57750d07-3c5e-4153-8b71-20e61cb5dc51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "\n",
    "import yfinance as yf\n",
    "yf.pdr_override() # <== that's all it takes :-)\n",
    "\n",
    "# download dataframe\n",
    "data = pdr.get_data_yahoo(\"SPY\", start=\"2017-01-01\", end=\"2017-04-30\", thread=False)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27392a4-22a2-4ea7-b1ad-36e493505bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "293bb5f2-02f1-4659-b99f-50f030f5eec3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from pandas_datareader import data as pdr\n",
    "from dask.dataframe import from_pandas\n",
    "from os.path import expanduser\n",
    "\n",
    "# get dataframe using folder and stock name\n",
    "# takes csv file and reads + returns the dataframe\n",
    "def get_dataframe(symbol):\n",
    "    return pd.read_csv(symbol)\n",
    "\n",
    "# create excel file using dask and yfinance\n",
    "# needs to have a time interval set by default\n",
    "# timeStart and timeEnd are for dates\n",
    "def create_excel(symbol, timeStart, timeEnd):\n",
    "\n",
    "    #get dataframe for pandas\n",
    "    pd = pdr.get_data_yahoo(symbol, start=timeStart, end=timeEnd)\n",
    "    \n",
    "    print (pd)\n",
    "    \n",
    "    #convert from pandas to dask dataframe\n",
    "    df = dd.from_pandas(pd, npartitions=3)\n",
    "    \n",
    "    #make filepath\n",
    "    home = expanduser(\"~\")\n",
    "    \n",
    "    filename = \"\\Desktop\\\\\" + symbol + \" \" + timeStart + \" to \" + timeEnd\n",
    "    \n",
    "    filepath = home + filename + \".csv\"\n",
    "    \n",
    "    print (\"Created in: \" + filepath)\n",
    "    \n",
    "    #convert to csv file\n",
    "    df.to_csv(filepath, single_file = True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d829ac-e1eb-4522-ba17-e6575841610a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_excel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RICKYW~1\\AppData\\Local\\Temp/ipykernel_9408/1064834902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SPY\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2017-02-01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2017-02-01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpopulate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2021\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_excel' is not defined"
     ]
    }
   ],
   "source": [
    "create_excel(\"SPY\", '2017-02-01', '2017-02-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a16473-cd3b-4685-ac74-23575b8d6fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import calendar\n",
    "import os\n",
    "from pandas_datareader import data as pdr\n",
    "from dask.dataframe import from_pandas\n",
    "from os.path import expanduser\n",
    "\n",
    "# need to create test for this \n",
    "# get dataframe using folder and stock name\n",
    "# takes csv file and reads + returns the dataframe\n",
    "def get_dataframe(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# create excel file using dask and yfinance\n",
    "# needs to have a time interval set by default\n",
    "# timeStart and timeEnd are for dates\n",
    "def create_excel(symbol, timeStart, timeEnd):\n",
    "\n",
    "    #get dataframe for pandas\n",
    "    pd = pdr.get_data_yahoo(symbol, start=timeStart, end=timeEnd)\n",
    "    \n",
    "    print (pd)\n",
    "    \n",
    "    #convert from pandas to dask dataframe\n",
    "    df = dd.from_pandas(pd, npartitions=3)\n",
    "    \n",
    "    #make filepath\n",
    "    filename = symbol + \"_\" + timeStart + \"_to_\" + timeEnd\n",
    "    \n",
    "    filepath = os.getcwd() + \"\\\\\" + symbol + \"\\\\\" + filename\n",
    "    \n",
    "    print (\"Created in: \" + filepath)\n",
    "    \n",
    "    #convert to csv file\n",
    "    df.to_csv(filepath, single_file = True)\n",
    "    return\n",
    "\n",
    "# creates a large set of data\n",
    "# timeSpan determines month or year\n",
    "# duration is the # of years/months you want the data for\n",
    "# user specifies which month and which year\n",
    "# NOTE: creating data per year and setting a month, the data created will always start at the given\n",
    "# --month for every year\n",
    "def populate_data(symbol, timeSpan, duration, dateYear, dateMonth):\n",
    "\n",
    "    #gets start and end times for specified time month-by-month\n",
    "    if 'm' in timeSpan:\n",
    "        for i in range(duration):\n",
    "            dates = convert_date(dateYear, dateMonth+i)\n",
    "            create_excel(symbol, dates[0], dates[1])\n",
    "            \n",
    "            \n",
    "    elif 'y' in timeSpan:\n",
    "        for i in range(duration):\n",
    "            for x in range(12):\n",
    "                #makes sure doesnt go over 12\n",
    "                if dateMonth+x < 13:\n",
    "                    dates = convert_date(dateYear+i, dateMonth+x)\n",
    "                    create_excel(symbol, dates[0], dates[1])\n",
    "\n",
    "    return\n",
    "\n",
    "# takes a year and a month\n",
    "# returns array w/ start and end of that month\n",
    "def convert_date(year, month):\n",
    "    \n",
    "    startDate = ''\n",
    "    endDate = calendar.monthrange(year, month)[1]\n",
    "    \n",
    "    if endDate < 10:\n",
    "        endDate = \"0\" + str(date)\n",
    "    \n",
    "    if month < 10:\n",
    "        month = \"0\" + str(month)\n",
    "    \n",
    "    endDate = str(year) + '-' + str(month) + '-' + str(endDate)\n",
    "    startDate = str(year) + '-' + str(month) + '-' + \"01\"\n",
    "    \n",
    "    dates = [startDate, endDate]\n",
    "    \n",
    "    print(dates)\n",
    "    \n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d5b554-17ec-4427-a946-1e9c43e7006f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2008-02-01', '2008-02-29']\n",
      "                  High         Low        Open       Close     Volume  \\\n",
      "Date                                                                    \n",
      "2008-02-01  139.610001  137.520004  137.940002  139.580002  206843600   \n",
      "2008-02-04  139.300003  137.639999  139.210007  137.820007  124694300   \n",
      "2008-02-05  136.250000  133.669998  135.940002  134.130005  286882500   \n",
      "2008-02-06  135.250000  132.410004  134.580002  133.050003  250792900   \n",
      "2008-02-07  134.789993  131.729996  131.800003  133.929993  297368100   \n",
      "2008-02-08  134.220001  132.100006  133.089996  133.070007  221643500   \n",
      "2008-02-11  134.229996  132.039993  133.100006  133.750000  188576300   \n",
      "2008-02-12  136.309998  133.979996  134.910004  134.990005  256654400   \n",
      "2008-02-13  137.059998  135.139999  136.009995  136.369995  181967800   \n",
      "2008-02-14  137.000000  134.789993  136.949997  135.169998  215207200   \n",
      "2008-02-15  135.220001  133.910004  134.500000  135.139999  154110300   \n",
      "2008-02-19  136.889999  134.610001  136.720001  135.520004  145190000   \n",
      "2008-02-20  136.550003  133.759995  133.990005  135.919998  220085700   \n",
      "2008-02-21  137.009995  134.070007  136.660004  134.789993  201051200   \n",
      "2008-02-22  135.850006  132.860001  134.970001  135.619995  205491000   \n",
      "2008-02-25  137.649994  134.779999  135.539993  137.330002  190107000   \n",
      "2008-02-26  138.949997  136.500000  136.750000  138.360001  212420700   \n",
      "2008-02-27  139.139999  137.410004  137.559998  138.220001  168395800   \n",
      "2008-02-28  137.960007  136.550003  137.240005  136.869995  170831100   \n",
      "2008-02-29  135.679993  132.779999  135.600006  133.820007  252715200   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2008-02-01  106.372528  \n",
      "2008-02-04  105.031242  \n",
      "2008-02-05  102.219116  \n",
      "2008-02-06  101.396072  \n",
      "2008-02-07  102.066689  \n",
      "2008-02-08  101.411301  \n",
      "2008-02-11  101.929504  \n",
      "2008-02-12  102.874542  \n",
      "2008-02-13  103.926208  \n",
      "2008-02-14  103.011703  \n",
      "2008-02-15  102.988815  \n",
      "2008-02-19  103.278397  \n",
      "2008-02-20  103.583267  \n",
      "2008-02-21  102.722084  \n",
      "2008-02-22  103.354630  \n",
      "2008-02-25  104.657814  \n",
      "2008-02-26  105.442764  \n",
      "2008-02-27  105.336052  \n",
      "2008-02-28  104.307259  \n",
      "2008-02-29  101.982895  \n",
      "Created in: C:\\Users\\Ricky Wei\\Desktop\\StockPrediction\\StockPrediction\\data\\Jupyter\\SPY\\SPY_2008-02-01_to_2008-02-29\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Ricky Wei\\\\Desktop\\\\StockPrediction\\\\StockPrediction\\\\data\\\\JupyterSPY_2008-02-01_to_2008-02-29'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RICKYW~1\\AppData\\Local\\Temp/ipykernel_15388/1508801448.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#populate_data('SPY','y', 2, 2010, 4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"SPY_2008-02-01_to_2008-02-29\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mget_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\RICKYW~1\\AppData\\Local\\Temp/ipykernel_15388/1696545499.py\u001b[0m in \u001b[0;36mget_dataframe\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# takes csv file and reads + returns the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# create excel file using dask and yfinance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricky wei\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricky wei\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricky wei\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricky wei\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricky wei\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricky wei\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricky wei\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricky wei\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Ricky Wei\\\\Desktop\\\\StockPrediction\\\\StockPrediction\\\\data\\\\JupyterSPY_2008-02-01_to_2008-02-29'"
     ]
    }
   ],
   "source": [
    "# NOTICE: POPULATE DATA WILL CREATE A NEW FOLDER\n",
    "populate_data('SPY','m', 1, 2008, 2)\n",
    "#populate_data('SPY','y', 2, 2010, 4)\n",
    "path = os.getcwd() + \"\\\\SPY\\\\\" + \"SPY_2008-02-01_to_2008-02-29\"\n",
    "get_dataframe(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d89ca-9c5f-4445-94c6-75f63c930617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3e053-941d-44b7-b392-d9c36a6fdb74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
